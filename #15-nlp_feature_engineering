## CHAPTER 1: Basic features and readability scores

a) One-hot encoding

# Print the features of df1
print(df1.columns)

# Perform one-hot encoding
df1 = pd.get_dummies(df1, columns=['feature 5'])

# Print the new features of df1
print(df1.columns)

# Print first five rows of df1
print(df1.head())
=> Output: <script.py> output:
    Index(['feature 1', 'feature 2', 'feature 3', 'feature 4', 'feature 5', 'label'], dtype='object')
    Index(['feature 1', 'feature 2', 'feature 3', 'feature 4', 'label', 'feature 5_female', 'feature 5_male'], dtype='object')
       feature 1  feature 2  feature 3  feature 4  label  feature 5_female  feature 5_male
    0     29.000          0          0    211.338      1                 1               0
    1      0.917          1          2    151.550      1                 0               1
    2      2.000          1          2    151.550      0                 1               0
    3     30.000          1          2    151.550      0                 0               1
    4     25.000          1          2    151.550      0                 1               0

b) Character count of Russian tweets

# Create a feature char_count
tweets['char_count'] = tweets['content'].apply(len)

# Print the average character count
print(tweets['char_count'].mean())
=> Great job! Notice that the average character count of these tweets is approximately 104, which is much higher than the overall average tweet length of around 40 characters. Depending on what you're working on, this may be something worth investigating into. For your information, there is research that indicates that fake news articles tend to have longer titles! Therefore, even extremely basic features such as character counts can prove to be very useful in certain applications.

c) Word count of TED talks

# Function that returns number of words in a string
def count_words(string):
	# Split the string into words
    words = string.split()
    
    # Return the number of words
    return len(words)

# Create a new feature word_count
ted['word_count'] = ted['transcript'].apply(count_words)

# Print the average word count of the talks
print(ted['word_count'].mean())
=> Output: <script.py> output:
    1987.1

d) Hashtags and mentions in Russian tweets

(i) # Function that returns number of hashtags in a string
def count_hashtags(string):
	# Split the string into words
    words = string.split()
    
    # Create a list of words that are hashtags
    hashtags = [word for word in words if word.startswith('#')]
    
    # Return number of hashtags
    return(len(hashtags))

# Create a feature hashtag_count and display distribution
tweets['hashtag_count'] = tweets['content'].apply(count_hashtags)
tweets['hashtag_count'].hist()
plt.title('Hashtag count distribution')
plt.show()

(ii) # Function that returns number of mentions in a string
def count_mentions(string):
	# Split the string into words
    words = string.split()
    
    # Create a list of words that are mentions
    mentions = [word for word in words if word.startswith('@')]
    
    # Return number of mentions
    return(len(mentions))

# Create a feature mention_count and display distribution
tweets['mention_count'] = tweets['content'].apply(count_mentions)
tweets['mention_count'].hist()
plt.title('Mention count distribution')
plt.show()

e) Readability of 'The Myth of Sisyphus'

# Import Readability
from readability import Readability

# Compute the readability scores object
readability_scores = Readability(sisyphus_essay)

# Print the flesch reading ease score
flesch = readability_scores.flesch()
print("The Flesch Reading Ease is %.2f" % (flesch.score))
=> Output: <script.py> output:
    The Flesch Reading Ease is 68.65
