## CHAPTER 1: INTRODUCTION TO CLUSTERING

a) Hierarchical clustering of Pokémon sightings

# Import linkage and fcluster functions
from scipy.cluster.hierarchy import linkage, fcluster

# Use the linkage() function to compute distance
Z = linkage(df[['x', 'y']], method='ward')

# Generate cluster labels
df['cluster_labels'] = fcluster(Z, 2, criterion='maxclust')

# Plot the points with seaborn
sns.scatterplot(x='x', y='y', hue='cluster_labels', data=df, palette='Set1')
plt.show()

b) K-Means clustering of Pokémon sightings

# Import kmeans and vq functions
from scipy.cluster.vq import kmeans, vq

# Compute cluster centers (k=2 for two clusters)
centroids, _ = kmeans(df[['x', 'y']], 2)

# Assign cluster labels
df['cluster_labels'], _ = vq(df[['x', 'y']], centroids)

# Plot the points with seaborn
sns.scatterplot(x='x', y='y', hue='cluster_labels', data=df, palette='Set1')
plt.show()

c) Normalizing football match goal data using whiten()

# Import the whiten function
from scipy.cluster.vq import whiten

goals_for = [4, 3, 2, 3, 1, 1, 2, 0, 1, 4]

# Use the whiten() function to standardize the data
scaled_data = whiten(goals_for)
print(scaled_data)

// Output:
    [3.07692308 2.30769231 1.53846154 2.30769231 0.76923077 0.76923077
     1.53846154 0.         0.76923077 3.07692308]

d) Visualizing the normalized data

import matplotlib.pyplot as plt

# Plot original data
plt.plot(goals_for, label='original')

# Plot scaled data
plt.plot(scaled_data, label='scaled')

# Show the legend in the plot
plt.legend()

# Display the plot
plt.show()
// Output: scaled data has lower variables

e) Normalizing and visualizing fractional numbers (interest rate changes)

# Import the whiten function
from scipy.cluster.vq import whiten
import matplotlib.pyplot as plt

# Prepare data
rate_cuts = [0.0025, 0.001, -0.0005, -0.001, -0.0005, 0.0025, -0.001, -0.0015, -0.001, 0.0005]

# Use the whiten() function to standardize the data
scaled_data = whiten(rate_cuts)

# Plot original data
plt.plot(rate_cuts, label='original')

# Plot scaled data
plt.plot(scaled_data, label='scaled')

plt.legend()
plt.show()

f) Normalizing and visualizing FIFA 18 player wage and value data

# Scale wage and value
fifa['scaled_wage'] = whiten(fifa['eur_wage'])
fifa['scaled_value'] = whiten(fifa['eur_value'])

# Plot the two columns in a scatter plot
fifa.plot(x='scaled_wage', y='scaled_value', kind = 'scatter')
plt.show()

# Check mean and standard deviation of scaled values
print(fifa[['scaled_wage', 'scaled_value']].describe())

//Output:
         scaled_wage  scaled_value
    count      1000.00       1000.00
    mean          1.12          1.31
    std           1.00          1.00
    min           0.00          0.00
    25%           0.47          0.73
    50%           0.85          1.02
    75%           1.41          1.54
    max           9.11          8.98


## CHAPTER 2: HIERARCHICAL CLUSTERING

a) Hierarchical clustering using the Ward method for Comic-Con footfall data

# Import the fcluster and linkage functions
from scipy.cluster.hierarchy import fcluster, linkage
import seaborn as sns
import matplotlib.pyplot as plt

# Use the linkage() function
distance_matrix = linkage(comic_con[['x_scaled', 'y_scaled']], method='ward', metric='euclidean')

# Assign cluster labels
comic_con['cluster_labels'] = fcluster(distance_matrix, 2, criterion='maxclust')

# Plot clusters
sns.scatterplot(x='x_scaled', y='y_scaled', hue='cluster_labels', data=comic_con, palette='Set1')
plt.show()

b) Hierarchical clustering using the single linkage method for Comic-Con footfall data

# Import the fcluster and linkage functions
from scipy.cluster.hierarchy import fcluster, linkage
import seaborn as sns
import matplotlib.pyplot as plt

# Use the linkage() function with the single method
distance_matrix = linkage(comic_con[['x_scaled', 'y_scaled']], method='single', metric='euclidean')

# Assign cluster labels
comic_con['cluster_labels'] = fcluster(distance_matrix, 2, criterion='maxclust')

# Plot clusters
sns.scatterplot(x='x_scaled', y='y_scaled', hue='cluster_labels', data=comic_con, palette='Set1')
plt.show()

c) Hierarchical clustering using the complete linkage method for Comic-Con footfall data

# Import the fcluster and linkage functions
from scipy.cluster.hierarchy import fcluster, linkage
import seaborn as sns
import matplotlib.pyplot as plt

# Use the linkage() function with the complete method
distance_matrix = linkage(comic_con[['x_scaled', 'y_scaled']], method='complete', metric='euclidean')

# Assign cluster labels
comic_con['cluster_labels'] = fcluster(distance_matrix, 2, criterion='maxclust')

# Plot clusters
sns.scatterplot(x='x_scaled', y='y_scaled', hue='cluster_labels', data=comic_con, palette='Set1')
plt.show()

d) Visualizing clusters using matplotlib

# Import the pyplot class
import matplotlib.pyplot as plt

# Define a colors dictionary for clusters
colors = {1: 'red', 2: 'blue'}

# Plot a scatter plot with cluster colors
comic_con.plot.scatter(x='x_scaled', 
                        y='y_scaled',
                        c=comic_con['cluster_labels'].apply(lambda x: colors[x]))

# Show the plot
plt.show()

e) Visualizing clusters using Seaborn

# Import the seaborn module
import seaborn as sns
import matplotlib.pyplot as plt

# Plot a scatter plot using seaborn
sns.scatterplot(x='x_scaled', 
                y='y_scaled', 
                hue='cluster_labels', 
                data=comic_con, 
                palette='Set1')

# Show the plot
plt.show()

f) Creating a dendrogram using the Comic-Con footfall data

# Import the dendrogram function
from scipy.cluster.hierarchy import dendrogram
import matplotlib.pyplot as plt

# Create a dendrogram
dn = dendrogram(distance_matrix)

# Display the dendrogram
plt.show()

g) Fitting FIFA 18 defender data into a hierarchical clustering algorithm

# Fit the data into a hierarchical clustering algorithm
distance_matrix = linkage(fifa[['scaled_sliding_tackle', 'scaled_aggression']], 'ward')

# Assign cluster labels to each row of data
fifa['cluster_labels'] = fcluster(distance_matrix, 3, criterion='maxclust')

# Display cluster centers of each cluster
print(fifa[['scaled_sliding_tackle', 'scaled_aggression', 'cluster_labels']].groupby('cluster_labels').mean())

# Create a scatter plot through seaborn
sns.scatterplot(x='scaled_sliding_tackle', y='scaled_aggression', hue='cluster_labels', data=fifa)
plt.show()

// Output:
<script.py> output:
                    scaled_sliding_tackle  scaled_aggression
    cluster_labels                                          
    1                                2.99               4.35
    2                                0.74               1.94
    3                                1.34               3.62


## CHAPTER 3: K-MEANS CLUSTERING

a) Performing K-means clustering on the Comic-Con dataset

# Import the kmeans and vq functions
from scipy.cluster.vq import kmeans, vq
import seaborn as sns
import matplotlib.pyplot as plt

# Generate cluster centers (k=2 for two clusters)
cluster_centers, distortion = kmeans(comic_con[['x_scaled', 'y_scaled']], 2)

# Assign cluster labels
comic_con['cluster_labels'], distortion_list = vq(comic_con[['x_scaled', 'y_scaled']], cluster_centers)

# Plot clusters
sns.scatterplot(x='x_scaled', y='y_scaled', hue='cluster_labels', data=comic_con, palette='Set1')
plt.show()

b) Applying the Elbow Method to find the optimal number of clusters in the Comic-Con dataset

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.cluster.vq import kmeans

# Initialize an empty list to store distortions
distortions = []
num_clusters = range(1, 7)

# Create a list of distortions from the kmeans function
for i in num_clusters:
    cluster_centers, distortion = kmeans(comic_con[['x_scaled', 'y_scaled']], i)
    distortions.append(distortion)

# Create a DataFrame with two lists - num_clusters, distortions
elbow_plot = pd.DataFrame({'num_clusters': num_clusters, 'distortions': distortions})

# Create a line plot of num_clusters and distortions
sns.lineplot(x='num_clusters', y='distortions', data=elbow_plot)
plt.xticks(num_clusters)
plt.xlabel("Number of Clusters")
plt.ylabel("Distortion")
plt.title("Elbow Method for Optimal Clusters")
plt.show()
// Output: there are two clusters

c) Applying the Elbow Method to a uniformly distributed dataset

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.cluster.vq import kmeans

# Initialize an empty list to store distortions
distortions = []
num_clusters = range(2, 7)

# Create a list of distortions from the kmeans function
for i in num_clusters:
    cluster_centers, distortion = kmeans(uniform_data[['x_scaled', 'y_scaled']], i)
    distortions.append(distortion)

# Create a DataFrame with two lists - num_clusters and distortions
elbow_plot = pd.DataFrame({'num_clusters': num_clusters, 'distortions': distortions})

# Create a line plot of num_clusters and distortions
sns.lineplot(x='num_clusters', y='distortions', data=elbow_plot)
plt.xticks(num_clusters)
plt.xlabel("Number of Clusters")
plt.ylabel("Distortion")
plt.title("Elbow Method on Uniform Data")
plt.show()
// Output: undetermined # of clusters (elbow not available)

d) Applying K-means clustering to the mouse-like dataset

# Import the kmeans and vq functions
from scipy.cluster.vq import kmeans, vq
import seaborn as sns
import matplotlib.pyplot as plt

# Generate cluster centers (k=3 for three clusters)
cluster_centers, distortion = kmeans(mouse[['x_scaled', 'y_scaled']], 3)

# Assign cluster labels
mouse['cluster_labels'], distortion_list = vq(mouse[['x_scaled', 'y_scaled']], cluster_centers)

# Plot clusters
sns.scatterplot(x='x_scaled', y='y_scaled', hue='cluster_labels', data=mouse, palette='Set1')
plt.show()

e) FIFA 18 defender clustering

# Set up a random seed in numpy
random.seed([1000,2000])

# Fit the data into a k-means algorithm
cluster_centers,_ = kmeans(fifa[['scaled_def', 'scaled_phy']], 3)

# Assign cluster labels
fifa['cluster_labels'], _ = vq(fifa[['scaled_def', 'scaled_phy']], cluster_centers)

# Display cluster centers 
print(fifa[['scaled_def', 'scaled_phy', 'cluster_labels']].groupby('cluster_labels').mean())

# Create a scatter plot through seaborn
sns.scatterplot(x='scaled_def', y='scaled_phy', hue='cluster_labels', data=fifa)
plt.show()

// Output: 
                   scaled_def  scaled_phy
    cluster_labels                        
    0                     3.74        8.87
    1                     1.87        7.08
    2                     2.10        8.94


## CHAPTER 4: CLUSTERING IN REAL WORLD

a) Extracting RGB values from an image

# Import image class of matplotlib
import matplotlib.image as img

# Read batman image and print dimensions
batman_image = img.imread('batman.jpg')
print(batman_image.shape)  # Print dimensions of the image matrix

# Initialize empty lists to store RGB values
r, g, b = [], [], []

# Store RGB values of all pixels in lists r, g, and b
for row in batman_image:
    for temp_r, temp_g, temp_b in row:
        r.append(temp_r)
        g.append(temp_g)
        b.append(temp_b)
// Output: (57, 90, 3)

b) Finding the optimal number of dominant colors using the Elbow Method

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.cluster.vq import kmeans

# Initialize an empty list to store distortions
distortions = []
num_clusters = range(1, 7)

# Create a list of distortions from the kmeans function
for i in num_clusters:
    cluster_centers, distortion = kmeans(batman_df[['scaled_red', 'scaled_blue', 'scaled_green']], i)
    distortions.append(distortion)

# Create a DataFrame with two lists, num_clusters and distortions
elbow_plot = pd.DataFrame({'num_clusters': num_clusters, 'distortions': distortions})

# Create a line plot of num_clusters and distortions
sns.lineplot(x='num_clusters', y='distortions', data=elbow_plot)
plt.xticks(num_clusters)
plt.xlabel("Number of Clusters")
plt.ylabel("Distortion")
plt.title("Elbow Method for Dominant Colors")
plt.show()

c) Displaying the dominant colors in the Batman image

import matplotlib.pyplot as plt

# Get standard deviations of each color
r_std, g_std, b_std = batman_df[['red', 'green', 'blue']].std()

# Initialize a list to store RGB values of cluster centers
colors = []

for cluster_center in cluster_centers:
    scaled_r, scaled_g, scaled_b = cluster_center
    # Convert each standardized value to scaled value in the range of 0-1
    colors.append((
        scaled_r * r_std / 255,
        scaled_g * g_std / 255,
        scaled_b * b_std / 255
    ))

# Display colors of cluster centers
plt.imshow([colors])
plt.axis("off")  # Hide axes for better visualization
plt.show()

d) Computing the TF-IDF of movie plots

# Import TfidfVectorizer class from sklearn
from sklearn.feature_extraction.text import TfidfVectorizer

# Initialize TfidfVectorizer with specified parameters
tfidf_vectorizer = TfidfVectorizer(min_df=0.1, max_df=0.75, max_features=50, tokenizer=remove_noise)

# Use the .fit_transform() method on the list plots
tfidf_matrix = tfidf_vectorizer.fit_transform(plots)

e) Finding the top terms in movie clusters using TF-IDF and K-Means clustering

import numpy as np
from scipy.cluster.vq import kmeans

num_clusters = 2  # Define the number of clusters

# Convert sparse matrix to dense format for k-means processing
dense_tfidf_matrix = tfidf_matrix.todense()

# Generate cluster centers using the kmeans function
cluster_centers, distortion = kmeans(dense_tfidf_matrix, num_clusters)

# Generate terms from the tfidf_vectorizer object
terms = tfidf_vectorizer.get_feature_names_out()

# Print top 3 terms for each cluster
for i in range(num_clusters):
    # Create a dictionary mapping terms to their importance in the cluster
    center_terms = dict(zip(terms, cluster_centers[i]))

    # Sort terms based on importance in descending order
    sorted_terms = sorted(center_terms, key=center_terms.get, reverse=True)

    # Print the top 3 terms in the cluster
    print(f"Cluster {i+1} top terms: {sorted_terms[:3]}")

// Output:
    Cluster 1 top terms: ['father', 'back', 'one']
    Cluster 2 top terms: ['police', 'man', 'killed']

f) Performing basic checks on clusters in the FIFA 18 dataset

# Print the size of the clusters
print(fifa.groupby('cluster_labels')['ID'].count())

# Print the mean value of wages in each cluster
print(fifa.groupby('cluster_labels')['eur_wage'].mean())

// Output:
    cluster_labels
    0     83
    1    107
    2     60
    Name: ID, dtype: int64
    cluster_labels
    0   132108.43
    1   130308.41
    2   117583.33
    Name: eur_wage, dtype: float64

g) Creating clusters of complete FIFA 18 players using K-means

# Create centroids with kmeans for 2 clusters
cluster_centers,_ = kmeans(fifa[scaled_features], 2)

# Assign cluster labels and print cluster centers
fifa['cluster_labels'], _ = vq(fifa[scaled_features], cluster_centers)
print(fifa.groupby('cluster_labels')[scaled_features].mean())

# Plot cluster centers to visualize clusters
fifa.groupby('cluster_labels')[scaled_features].mean().plot(legend=True, kind='bar')
plt.show()

# Get the name column of first 5 players in each cluster
for cluster in fifa['cluster_labels'].unique():
    print(cluster, fifa[fifa['cluster_labels'] == cluster]['name'].values[:5])

// Output:
                   scaled_pac  scaled_sho  scaled_pas  scaled_dri  scaled_def  scaled_phy
    cluster_labels                                                                        
    0                     6.68        5.43        8.46        8.51        2.50        8.34
    1                     5.44        3.66        7.17        6.76        3.97        9.21
    0 ['Cristiano Ronaldo' 'L. Messi' 'Neymar' 'L. Suárez' 'M. Neuer']
    1 ['Sergio Ramos' 'G. Chiellini' 'D. Godín' 'Thiago Silva' 'M. Hummels']
