## CHAPTER 1: TIME SERIES AND ML PRIMER

a) Plotting the values of two time series without the time component.

# Print the first 5 rows of data
print(data.head())

print(data2.head())

# Plot the time series in each dataset
fig, axs = plt.subplots(2, 1, figsize=(5, 10))
data.iloc[:1000].plot(x='time', y='data_values', ax=axs[0])
data2.iloc[:1000].plot(x='time', y='data_values', ax=axs[1])
plt.show()

=> Each time series has a very different sampling frequency (the amount of time between samples). The first is daily stock market data, and the second is an audio waveform.

b) Use the Iris dataset to train a classification model using scikit-learn

# Print the first 5 rows for inspection
print(data.head())

from sklearn.svm import LinearSVC

# Construct data for the model
X = data[['petal length (cm)', 'petal width (cm)']]
y = data[['target']]

# Fit the model
model = LinearSVC()
model.fit(X, y)

c) Use a trained classifier to predict the type of flower based on petal dimensions.

# Import necessary libraries
import matplotlib.pyplot as plt

# Create input array for predictions
X_predict = targets[['petal length (cm)', 'petal width (cm)']]

# Predict with the trained model (assuming `model` is already trained)
predictions = model.predict(X_predict)
print(predictions)

# Visualize predictions
plt.scatter(X_predict['petal length (cm)'], X_predict['petal width (cm)'],
            c=predictions, cmap=plt.cm.coolwarm)
plt.title("Predicted class values")
plt.xlabel("Petal Length (cm)")
plt.ylabel("Petal Width (cm)")
plt.show()
// Note: the output of your predictions are all integers, representing that datapoint's predicted class.
Output: [2 2 2 1 1 2 2 2 2 1 2 1 1 2 1 1 2 1 2 2]

d) Predict average number of rooms per dwelling (AveRooms) based on median house value (MedHouseVal)

from sklearn import linear_model

# Prepare input (X) and output (y) DataFrames
X = housing[['MedHouseVal']]  # Independent variable (feature)
y = housing[['AveRooms']]     # Dependent variable (target)

# Initialize and fit the linear regression model
model = linear_model.LinearRegression()
model.fit(X, y)

e) Use the trained regression model to predict average number of rooms per dwelling (AveRooms) for new median house values.

# Reshape new_inputs into a 2D array (required for scikit-learn)
new_inputs_reshaped = new_inputs.reshape(-1, 1)

# Generate predictions using the trained model
predictions = model.predict(new_inputs_reshaped)

# Visualize the inputs and predicted values
plt.scatter(new_inputs, predictions, color='r', s=3)
plt.xlabel('Median House Value (MedHouseVal)')
plt.ylabel('Predicted Average Rooms (AveRooms)')
plt.title('Predictions from Regression Model')
plt.show()

f) Load and visualize a heartbeat sound waveform from the dataset.

import librosa as lr
from glob import glob
import numpy as np
import matplotlib.pyplot as plt

# List all the .wav files in the directory
audio_files = glob(data_dir + '/*.wav')

# Read in the first audio file
audio, sfreq = lr.load(audio_files[0])

# Create a time array
time = np.arange(0, len(audio)) / sfreq

# Plot the audio waveform
fig, ax = plt.subplots()
ax.plot(time, audio)
ax.set(xlabel='Time (s)', ylabel='Sound Amplitude', title='Heartbeat Sound Waveform')
plt.show()
// Note: A common procedure in machine learning is to separate the datapoints with lots of stuff happening from the ones that don't.

g) Load and visualize company market value over time.

import pandas as pd
import matplotlib.pyplot as plt

# Read in the data
data = pd.read_csv('prices.csv', index_col=0)

# Convert the index of the DataFrame to datetime
data.index = pd.to_datetime(data.index)
print(data.head())

# Loop through each column and plot its values over time
fig, ax = plt.subplots(figsize=(12,6))
for column in data.columns:
    data[column].plot(ax=ax, label=column)

# Add legend and labels
ax.legend()
ax.set(xlabel="Time", ylabel="Market Value", title="Company Market Value Over Time")
plt.show()
// Output:
                  AAPL  FB   NFLX      V    XOM
    time                                       
    2010-01-04  214.01 NaN  53.48  88.14  69.15
    2010-01-05  214.38 NaN  51.51  87.13  69.42
    2010-01-06  210.97 NaN  53.32  85.96  70.02
    2010-01-07  210.58 NaN  52.40  86.76  69.80
    2010-01-08  211.98 NaN  53.30  87.00  69.52


## CHAPTER 2: TIME SERIES AS INPUTS TO A MODEL

a) Compare normal vs. abnormal heartbeats by plotting audio waveforms.

import numpy as np
import matplotlib.pyplot as plt

fig, axs = plt.subplots(3, 2, figsize=(15, 7), sharex=True, sharey=True)

# Calculate the time array
time = np.arange(normal.shape[0]) / sfreq

# Stack the normal/abnormal audio so you can loop and plot
stacked_audio = np.hstack([normal, abnormal]).T

# Loop through each audio file / ax object and plot
for iaudio, ax in zip(stacked_audio, axs.T.ravel()):
    ax.plot(time, iaudio)

# Show the plot with appropriate titles
show_plot_and_make_titles()

b) Average across multiple heartbeat audio files for normal and abnormal classes and visualize the patterns over time.

import numpy as np
import matplotlib.pyplot as plt

# Average across the audio files of each DataFrame
mean_normal = np.mean(normal, axis=1)
mean_abnormal = np.mean(abnormal, axis=1)

# Plot each average over time
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3), sharey=True)

ax1.plot(time, mean_normal)
ax1.set(title="Normal Data")

ax2.plot(time, mean_abnormal)
ax2.set(title="Abnormal Data")

plt.show()

c) Train a Linear SVM classifier to predict normal vs. abnormal heartbeats based on raw audio data.

from sklearn.svm import LinearSVC

# Initialize and fit the model
model = LinearSVC()
model.fit(X_train, y_train)

# Generate predictions and score them manually
predictions = model.predict(X_test)
print(sum(predictions == y_test.squeeze()) / len(y_test))
// Output: 0.5555555555555556; Note that our predictions didn't do so well because the features you're using as inputs to the model (raw data) aren't very good at differentiating classes. Next, you'll explore how to calculate some more complex features that may improve the results.

d) Smooth and rectify the raw audio signal to make the total sound energy more distinguishable.

# Plot the raw data first
audio.plot(figsize=(10, 5))
plt.show()

# Rectify the audio signal
audio_rectified = audio.apply(np.abs)

# Plot the result
audio_rectified.plot(figsize=(10, 5))
plt.show()

# Smooth by applying a rolling mean
audio_rectified_smooth = audio_rectified.rolling(50).mean()

# Plot the result
audio_rectified_smooth.plot(figsize=(10, 5))
plt.show()

e) Extract statistical features from the smoothed and rectified heartbeat audio signals and use cross-validation for model evaluation.

import numpy as np
from sklearn.model_selection import cross_val_score

# Calculate statistical features from the smoothed envelope
means = np.mean(audio_rectified_smooth, axis=0)
stds = np.std(audio_rectified_smooth, axis=0)
maxs = np.max(audio_rectified_smooth, axis=0)

# Stack the features together
X = np.column_stack([means, stds, maxs])
y = labels.reshape(-1, 1)

# Fit the model and evaluate with cross-validation
percent_score = cross_val_score(model, X, y, cv=5)
print(np.mean(percent_score))
// Output: 0.7166666666666667; This model is both simpler (only 3 features) and more understandable (features are simple summary statistics of the data).

f) Compute tempo-based features from heartbeat audio using librosa, then extract statistical features (mean, standard deviation, max) from the tempogram.

import librosa as lr
import numpy as np

# Calculate the tempogram of the sounds
tempos = []
for col, i_audio in audio.items():
    tempos.append(lr.beat.tempo(i_audio.values, sr=sfreq, hop_length=2**6, aggregate=None))

# Convert the list to a numpy array
tempos = np.array(tempos)

# Compute statistical features from the tempogram
tempos_mean = tempos.mean(axis=-1)
tempos_std = tempos.std(axis=-1)
tempos_max = tempos.max(axis=-1)

# Create the X and y arrays
X = np.column_stack([means, stds, maxs, tempos_mean, tempos_std, tempos_max])
y = labels.reshape(-1, 1)

# Fit the model and score on testing data
percent_score = cross_val_score(model, X, y, cv=5)
print(np.mean(percent_score))
// Output: 0.5; Note: predictive power may not have gone up because this dataset is quite small, but having a more rich feature representation of audio for the model

g) Compute the spectrogram of a heartbeat audio file using the Short-Time Fourier Transform (STFT) from librosa.

# Import the STFT function
from librosa.core import stft

# Prepare the STFT
HOP_LENGTH = 2**4  # Hop length determines how much we slide the window
spec = stft(audio, hop_length=HOP_LENGTH, n_fft=2**7)  # Compute the STFT

from librosa.core import amplitude_to_db
from librosa.display import specshow

# Convert into decibels
spec_db = amplitude_to_db(spec)

# Compare the raw audio to the spectrogram of the audio
fig, axs = plt.subplots(2, 1, figsize=(10, 10), sharex=True)
axs[0].plot(time, audio)
specshow(spec_db, sr=sfreq, x_axis='time', y_axis='hz', hop_length=HOP_LENGTH, ax=axs[1])
plt.show()

h)


