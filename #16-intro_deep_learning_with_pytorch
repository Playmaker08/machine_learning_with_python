## CHAPTER 1: INTRO TO PYTORCH

a) Getting started with PyTorch tensors
Tensors are PyTorch's core data structure and the foundation of deep learning. They're similar to NumPy arrays but have unique features. Here you have a Python list named temperatures containing daily readings from two weather stations. 

# Import PyTorch
import torch

temperatures = [[72, 75, 78], [70, 73, 76]]

# Create a tensor from temperatures
temp_tensor = torch.tensor(temperatures)

print(temp_tensor)
=> Output: <script.py> output:
    tensor([[72, 75, 78],
            [70, 73, 76]])

b) Checking and adding tensors
While collecting temperature data, you notice the readings are off by two degrees. Add two degrees to the temperatures tensor after verifying its shape and data type with torch to ensure compatibility with the adjustment tensor.

adjustment = torch.tensor([[2, 2, 2], [2, 2, 2]])

# Display the shape of the adjustment tensor
print("Adjustment shape:", adjustment.shape)

# Display the type of the adjustment tensor
print("Adjustment type:", adjustment.dtype)

print("Temperatures shape:", temperatures.shape)
print("Temperatures type:", temperatures.dtype)

# Add the temperatures and adjustment tensors
corrected_temperatures = temperatures + adjustment
print("Corrected temperatures:", corrected_temperatures)
=> Output: <script.py> output:
    Adjustment shape: torch.Size([2, 3])
    Adjustment type: torch.int64
    Temperatures shape: torch.Size([2, 3])
    Temperatures type: torch.int64

    Corrected temperatures: tensor([[74, 77, 80],
            [72, 75, 78]])

c) Linear layer network
Neural networks often contain many layers, but most of them are linear layers. Understanding a single linear layer helps you grasp how they work before adding complexity.

import torch
import torch.nn as nn

input_tensor = torch.tensor([[0.3471, 0.4547, -0.2356]])

# Create a Linear layer
linear_layer = nn.Linear(
                         in_features=3, 
                         out_features=2
                         )

# Pass input_tensor through the linear layer
output = linear_layer(input_tensor)

print(output)
=> Output: <script.py> output:
    tensor([[0.2647, 0.4096]], grad_fn=<AddmmBackward0>)

Note: In a linear model, weights and biases play a crucial role in determining how inputs are transformed into outputs. Weights determine how much influence each input has on the neuron's output.

d) Implement a small neural network containing two linear layers in sequence

import torch
import torch.nn as nn

input_tensor = torch.Tensor([[2, 3, 6, 7, 9, 3, 2, 1]])

# Create a container for stacking linear layers
model = nn.Sequential(nn.Linear(8, 4),
                      nn.Linear(4, 1)
                     )

output = model(input_tensor)
print(output)
=> Output: <script.py> output:
    tensor([[-1.4931]], grad_fn=<AddmmBackward0>)

e) Counting the number of parameters

import torch.nn as nn

model = nn.Sequential(nn.Linear(9, 4),
                      nn.Linear(4, 2),
                      nn.Linear(2, 1))

total = 0

# Calculate the number of parameters in the model
for p in model.parameters():
  total += p.numel()
  
print(f"The number of parameters in the model is {total}")
=> Output: <script.py> output:
    The number of parameters in the model is 53


## CHAPTER 2: NEURAL NETWORK ARCHITECTURE AND HYPERPARAMETERS

Note: A neural network with a single linear layer followed by a sigmoid activation is similar to a logistic regression model

The sigmoid and softmax functions are key activation functions in deep learning, often used as the final step in a neural network.

Sigmoid is for binary classification
Softmax is for multi-class classification

a) Create a sigmoid function and apply it on input_tensor

input_tensor = torch.tensor([[2.4]])
sigmoid = nn.Sigmoid()
probability = sigmoid(input_tensor)
print(probability)

=> Output: <script.py> output:
    tensor([[0.9168]])

b) # Create a softmax function and apply it on input_tensor

input_tensor = torch.tensor([[1.0, -6.0, 2.5, -0.3, 1.2, 0.8]])

softmax = nn.Softmax(dim=-1)
probabilities = softmax(input_tensor)
print(probabilities)

=> Output: <script.py> output:
    tensor([[1.2828e-01, 1.1698e-04, 5.7492e-01, 3.4961e-02, 1.5669e-01, 1.0503e-01]])

c) Building a binary classifier in PyTorch

import torch
import torch.nn as nn

input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])

# Implement a neural network for binary classification
model = nn.Sequential(
  nn.Linear(8, 1),
  nn.Sigmoid()
)

output = model(input_tensor)
print(output)

=> Output: <script.py> output:
    tensor([[0.7353]], grad_fn=<SigmoidBackward0>)

d) From regression to multi-class classification

# Create a 4-layer linear network that takes 11 input features from input_tensor and produces a single regression output.
import torch
import torch.nn as nn

input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])

# Implement a neural network with exactly four linear layers
model = nn.Sequential(
  nn.Linear(11, 20),
  nn.Linear(20, 12),
  nn.Linear(12, 6),
  nn.Linear(6, 1)  
)

output = model(input_tensor)
print(output)

# Update network below to perform a multi-class classification with four labels
model = nn.Sequential(
  nn.Linear(11, 20),
  nn.Linear(20, 12),
  nn.Linear(12, 6),
  nn.Linear(6, 4), 
  nn.Softmax(dim=-1)
)

output = model(input_tensor)
print(output)

=> Output: <script.py> output:
    tensor([[0.0250, 0.5338, 0.1802, 0.2611]], grad_fn=<SoftmaxBackward0>)

e) Creating one-hot encoded labels

One-hot encoding converts a single integer label into a vector with N elements, where N is the number of classes. This vector contains zeros and a one at the correct position.
Cross-entropy loss is a widely used method to measure classification loss. In this exercise, you’ll calculate cross-entropy loss in PyTorch using:

y: the ground truth label.
scores: a vector of predictions before softmax.
=> Loss functions help neural networks learn by measuring prediction errors.

y = 1
num_classes = 3

# Create the one-hot encoded vector using NumPy
one_hot_numpy = np.array([0, 1, 0])

# Create the one-hot encoded vector using PyTorch
one_hot_pytorch = F.one_hot(torch.tensor(y), num_classes=num_classes)

print("One-hot vector using NumPy:", one_hot_numpy)
print("One-hot vector using PyTorch:", one_hot_pytorch)

=> Output: <script.py> output:
    One-hot vector using NumPy: [0 1 0]
    One-hot vector using PyTorch: tensor([0, 1, 0])

f) Calculating cross entropy loss

import torch
import torch.nn.functional as F
from torch.nn import CrossEntropyLoss

y = [2]
scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])

# Create a one-hot encoded vector of the label y
one_hot_label = F.one_hot(torch.tensor(y), num_classes=4)

# Create the cross entropy loss function
criterion = CrossEntropyLoss()

# Calculate the cross entropy loss
loss = criterion(scores.double(), one_hot_label.double())
print(loss)

=> Output: <script.py> output:
    tensor(8.0619, dtype=torch.float64)

g) Accessing the model parameters

model = nn.Sequential(nn.Linear(16, 8),
                      nn.Linear(8, 2)
                     )

# Access the weight of the first linear layer
weight_0 = model[0].weight
print("Weight of the first layer:", weight_0)

# Access the bias of the second linear layer
bias_1 = model[1].bias
print("Bias of the second layer:", bias_1)

=> Output: <script.py> output:
    Weight of the first layer: Parameter containing:
    tensor([[-0.2474, -0.1837,  0.1161,  0.0262, -0.1423,  0.0670,  0.0421,  0.1149,
              0.1479, -0.0976, -0.0620, -0.1398,  0.0773, -0.0710,  0.1472, -0.0547],
            [ 0.0856,  0.0698, -0.1501, -0.1436,  0.0518, -0.2081,  0.2170,  0.2135,
              0.2282,  0.1349,  0.0628,  0.1530, -0.1893, -0.1616,  0.1041,  0.0316],
            [-0.2429, -0.1469, -0.1053,  0.0937, -0.1355, -0.0124,  0.1970, -0.0895,
             -0.0654,  0.0436, -0.1414, -0.1710,  0.0442, -0.0213, -0.1406, -0.1138],
            [-0.1642,  0.0252, -0.0772, -0.1645, -0.0946,  0.0551, -0.0503, -0.0929,
              0.1288,  0.0086, -0.1701, -0.1722,  0.2471,  0.0508,  0.2494, -0.0811],
            [-0.1996, -0.2287, -0.1312, -0.1041, -0.0490,  0.0984, -0.0774,  0.0225,
              0.0498,  0.0225,  0.0910, -0.0463,  0.0598,  0.0886, -0.1058, -0.0943],
            [-0.0992,  0.2024,  0.1520, -0.0972, -0.1161,  0.2192, -0.0716, -0.0181,
              0.2365,  0.2371, -0.0715,  0.1469, -0.1789,  0.1610, -0.0047,  0.1644],
            [ 0.1842,  0.1793, -0.2441, -0.0317, -0.1965, -0.1783,  0.0022,  0.1221,
             -0.0556,  0.2451,  0.0762, -0.2298, -0.2442,  0.0310,  0.0820, -0.0343],
            [-0.0598,  0.0873, -0.0679,  0.0401, -0.0036,  0.0370, -0.1217,  0.1866,
              0.1062, -0.0703,  0.0783, -0.2337, -0.1862, -0.0437, -0.0830, -0.1718]],
           requires_grad=True)
    Bias of the second layer: Parameter containing:
    tensor([-0.0686,  0.0167], requires_grad=True)

h) Updating the weights manually

weight0 = model[0].weight
weight1 = model[1].weight
weight2 = model[2].weight

# Access the gradients of the weight of each linear layer
grads0 = weight0.grad
grads1 = weight1.grad
grads2 = weight2.grad

# Update the weights using the learning rate and the gradients
weight0 = weight0 - lr * grads0
weight1 = weight1 - lr * grads1
weight2 = weight2 - lr * grads2

i) Using the PyTorch optimizer

# Create the optimizer
optimizer = optim.SGD(model.parameters(), lr=0.001)

loss = criterion(pred, target)
loss.backward()

# Update the model's parameters using the optimizer
optimizer.step()


## CHAPTER 3: TRAINING A NEURAL NETWORK WITH PYTORCH

a) Using TensorDataset

Structuring your data into a dataset is one of the first steps in training a PyTorch neural network. TensorDataset simplifies this by converting NumPy arrays into a format PyTorch can use.
The DataLoader class is essential for efficiently handling large datasets. It speeds up training, optimizes memory usage, and stabilizes gradient updates, making deep learning models more effective.

import torch
from torch.utils.data import TensorDataset

X = animals.iloc[:, 1:-1].to_numpy()  
y = animals.iloc[:, -1].to_numpy()

# Create a dataset
dataset = TensorDataset(torch.tensor(X), torch.tensor(y))

# Print the first sample
input_sample, label_sample = dataset[0]
print('Input sample:', input_sample)
print('Label sample:', label_sample)

=> Output: <script.py> output:
    Input sample: tensor([0, 1, 1, 0, 0, 2, 1])
    Label sample: tensor(0)

b) Using DataLoader

from torch.utils.data import DataLoader

# Create a DataLoader
dataloader = DataLoader(dataset, batch_size=2, shuffle=True)

# Iterate over the dataloader
for batch_inputs, batch_labels in dataloader:
    print('batch_inputs:', batch_inputs)
    print('batch_labels:', batch_labels)

=> Output: <script.py> output:
    batch_inputs: tensor([[0, 1, 1, 0, 1, 2, 1],
            [0, 0, 1, 0, 1, 4, 1]])
    batch_labels: tensor([0, 2])
    batch_inputs: tensor([[1, 0, 0, 1, 0, 4, 1],
            [1, 0, 0, 1, 1, 4, 1]])
    batch_labels: tensor([1, 1])
    batch_inputs: tensor([[0, 1, 1, 0, 0, 2, 1]])
    batch_labels: tensor([0])

TRAINING A NEURAL NETWORK
To train a neural network, follow these essential steps:

1. Build the model
Define the architecture of your neural network using layers and activation functions.
2. Select a loss function
Choose an appropriate loss function to measure the model’s prediction error (e.g., MSE for regression, CrossEntropy for classification).
3. Prepare the dataset
Load and preprocess the data, then divide it into training, validation, and test sets as needed.
4. Choose an optimizer
Select an optimization algorithm (e.g., SGD, Adam) that will update the model’s weights based on computed gradients.
5. Run the training loop
For each epoch:
Forward pass: Pass the input data through the model to compute predictions and calculate the loss.
Backward pass: Use backpropagation to compute gradients of the loss with respect to model parameters.
Update weights: Apply the optimizer to adjust the model’s parameters based on the gradients.
=> This process is repeated over multiple epochs until the model converges or reaches satisfactory performance.

c) Using the MSELoss

For regression problems, you often use Mean Squared Error (MSE) as a loss function instead of cross-entropy. MSE calculates the squared difference between predicted values (y_pred) and actual values (y).

y_pred = np.array([3, 5.0, 2.5, 7.0]) 
y = np.array([3.0, 4.5, 2.0, 8.0])   

# Calculate MSE using NumPy
mse_numpy = np.mean((y_pred - y)**2)

# Create the MSELoss function in PyTorch
criterion = nn.MSELoss()

# Calculate MSE using PyTorch
mse_pytorch = criterion(torch.tensor(y_pred), torch.tensor(y))

print("MSE (NumPy):", mse_numpy)
print("MSE (PyTorch):", mse_pytorch)
=> Output: <script.py> output:
    MSE (NumPy): 0.375
    MSE (PyTorch): tensor(0.3750, dtype=torch.float64)

d) Writing a training loop

# Loop over the number of epochs and the dataloader
for i in range(num_epochs):
  for data in dataloader:
    # Set the gradients to zero
    optimizer.zero_grad()  
    # Run a forward pass
    feature, target = data
    prediction = model(feature)    
    # Compute the loss
    loss = criterion(prediction, target)    
    # Compute the gradients
    loss.backward()
    # Update the model's parameters
    optimizer.step()
show_results(model, dataloader)

=> Output: <script.py> output:
    Ground truth salary: 0.195. Predicted salary: 0.098.
    Ground truth salary: 0.061. Predicted salary: 0.114.
    Ground truth salary: 0.278. Predicted salary: 0.072.
    Ground truth salary: 0.083. Predicted salary: 0.108.
    Ground truth salary: 0.205. Predicted salary: 0.072.
    Ground truth salary: 0.040. Predicted salary: 0.072.
    Ground truth salary: 0.114. Predicted salary: 0.077.
    Ground truth salary: 0.147. Predicted salary: 0.087.
    Ground truth salary: 0.055. Predicted salary: 0.087.
    Ground truth salary: 0.151. Predicted salary: 0.072.
    Ground truth salary: 0.151. Predicted salary: 0.072.
    Ground truth salary: 0.188. Predicted salary: 0.072.

e) Implementing ReLU

The Rectified Linear Unit (ReLU) is a widely-used activation function in deep learning, solving challenges like the vanishing gradients problem.
ReLU: POSITIVE inputs - output = input; NEGATIVE inputs - output is 0 
Leaky ReLU: POSITIVE inputs - output = input; NEGATIVE inputs - scaled by small coefficient (0.01 default)

# Create a ReLU function with PyTorch
relu_pytorch = nn.ReLU()

x_pos = torch.tensor(2.0)
x_neg = torch.tensor(-3.0)

# Apply the ReLU function to the tensors
output_pos = relu_pytorch(x_pos)
output_neg = relu_pytorch(x_neg)

print("ReLU applied to positive value:", output_pos)
print("ReLU applied to negative value:", output_neg)

=> Output: <script.py> output:
    ReLU applied to positive value: tensor(2.)
    ReLU applied to negative value: tensor(0.)

f) Implementing leaky ReLU

While ReLU is widely used, it sets negative inputs to 0, resulting in null gradients for those values. This can prevent parts of the model from learning. Leaky ReLU overcomes this by allowing small gradients for negative inputs, controlled by the negative_slope parameter. Instead of 0, negative inputs are scaled by this small value, keeping the model's learning active.

# Create a leaky relu function in PyTorch
leaky_relu_pytorch = nn.LeakyReLU(negative_slope=0.05)

x = torch.tensor(-2.0)
# Call the above function on the tensor x
output = leaky_relu_pytorch(x)
print(output)
=> Output: <script.py> output:
    tensor(-0.1000)

*** Learning Rate
Controls the step size in weight updates.
If too high → causes poor performance (overshooting optimal values).
If too low → leads to slow training (takes longer to converge).
Typical range: 0.01 and 0.0001

*** Momentum
Controls the inertia of the optimizer’s updates.
Helps escape local minima by carrying forward movement from previous steps.
If too small → optimizer can get stuck.
Typical range: 0.85 to 0.99
Keeps step size large when previous steps were also large, even if the current gradient is small.

g) Experimenting with learning rate

In this exercise, your goal is to find the optimal learning rate such that the optimizer can find the minimum of the non-convex function x^4 + x^3 - 5x^2 in ten steps. You will experiment with three different learning rate values between 0.001 to 0.1.

# Try a first learning rate value
lr0 = 0.005
optimize_and_plot(lr=lr0)
# Try a second learning rate value
lr1 = 0.1
optimize_and_plot(lr=lr1)
# Try a third learning rate value
lr2 = 0.09
optimize_and_plot(lr=lr2)
=>  A learning rate around 0.09 gets you closest to the global minimum.

h) Experimenting with momentum

In this exercise, your goal is to find the optimal momentum such that the optimizer can find the minimum of the following non-convex function x^4 + x^3 - 5x^2 in 20 steps. You will experiment with two different momentum value, with the learning rate is fixed at 0.01.

# Try a first value for momentum
mom0 = 0.85
optimize_and_plot(momentum=mom0)
# Try a second value for momentum
mom1 = 0.95
optimize_and_plot(momentum=mom1)
=> Momentum and learning rate are critical to the training of your neural network. A good rule of thumb is to start with a learning rate of 0.001 and a momentum of 0.95.


## CHAPTER 4: EVALUATING AND IMPROVING MODELS

*** Fine-tuning process:
Find a model trained on a similar task
Load pre-trained weights
Freeze (or not) some of the layers in the model
Train with a smaller learning rate
Look at the loss values and see if the learning rate needs to be adjusted

a) Freeze layers of a model

You are about to fine-tune a model on a new task after loading pre-trained weights. The model contains three linear layers. However, because your dataset is small, you only want to train the last linear layer of this model and freeze the first two linear layers.

for name, param in model.named_parameters():
  
    # Check for first layer's weight
    if name == '0.weight':
   
        # Freeze this weight
        param.requires_grad = False
        
    # Check for second layer's weight
    if name == '1.weight':
      
        # Freeze this weight
        param.requires_grad = False

b) Layer initialization

The initialization of the weights of a neural network has been the focus of researchers for many years. When training a network, the method used to initialize the weights has a direct impact on the final performance of the network.

layer0 = nn.Linear(16, 32)
layer1 = nn.Linear(32, 64)

# Use uniform initialization for layer0 and layer1 weights
nn.init.uniform_(layer0.weight)
nn.init.uniform_(layer1.weight)

model = nn.Sequential(layer0, layer1)

c) Writing the evaluation loop

# Set the model to evaluation mode
model.eval()
validation_loss = 0.0

with torch.no_grad():
  for features, labels in validationloader:
      outputs = model(features)
      loss = criterion(outputs, labels)
      # Sum the current loss to the validation_loss variable
      validation_loss += loss.item()
      
# Calculate the mean loss value
validation_loss_epoch = validation_loss / len(validationloader)
print(validation_loss_epoch)

# Set the model back to training mode
model.train()
=> Output: <script.py> output:
    0.904186356605755

d) Calculating accuracy using torchmetrics

# Create accuracy metric
metric = torchmetrics.Accuracy(task="multiclass", num_classes=3)
for features, labels in dataloader:
    outputs = model(features)
    
    # Calculate accuracy over the batch
    metric.update(outputs, labels.argmax(dim=-1))
    
# Calculate accuracy over the whole epoch
accuracy = metric.compute()
print(f"Accuracy on all data: {accuracy}")

# Reset metric for the next epoch
metric.reset()
plot_errors(model, dataloader)              
=> Output: <script.py> output:
    Accuracy on all data: 0.6901408433914185

e) Experimenting with dropout
Dropout helps prevent overfitting by randomly setting some output values to zero during training. 

# Model with Dropout
model = nn.Sequential(
    nn.Linear(8, 6),
    nn.Linear(6, 4),
    nn.Dropout(p=0.5))

# Forward pass in training mode (Dropout active)
model.train()
output_train = model(features)

# Forward pass in evaluation mode (Dropout disabled)
model.eval()
output_eval = model(features)

# Print results
print("Output in train mode:", output_train)
print("Output in eval mode:", output_eval)
=> Output: <script.py> output:
    Output in train mode: tensor([[0.3335, 0.0000, 0.0000, -0.0000]], grad_fn=<MulBackward0>)
    Output in eval mode: tensor([[ 0.1667,  0.8695,  0.8360, -0.6130]], grad_fn=<AddmmBackward0>)

*** Maximizing performance
* Initial Checks
Determine if the problem can be solved.
Set a performance baseline.
Aim to improve performance on the validation set.
* Steps to Maximize Performance
Overfit the training set – ensure the model can learn patterns from training data.
Reduce overfitting – improve generalization to unseen data.
Fine-tune hyperparameters – adjust settings for optimal performance.

f) Implementing random search

values = []
for idx in range(10):
    # Randomly sample a learning rate factor 2 and 4
    factor = np.random.uniform(2, 4)
    lr = 10 ** -factor
    
    # Randomly sample a momentum between 0.85 and 0.99
    momentum = np.random.uniform(0.85, 0.99)
    
    values.append((lr, momentum))
    
plot_hyperparameter_search(values)
